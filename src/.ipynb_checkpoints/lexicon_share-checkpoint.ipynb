{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate share of CORAAL/VOC text in ASR lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('..')\n",
    "base_folder = os.getcwd()+'/' #'~/fair-speech/release/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import previously generated transcript WER values\n",
    "\n",
    "clean_transcripts_wer = pd.read_csv(base_folder + 'output/transcribed_wer_usable_matched_punctuation.csv')\n",
    "clean_transcripts_wer = clean_transcripts_wer.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into AAVE and White samples\n",
    "\n",
    "def split_white_black(all_trans):\n",
    "    black_stack = all_trans[all_trans['black_flag']==1]\n",
    "    white_stack = all_trans[all_trans['black_flag']==0]\n",
    "    #black_stack = all_trans[all_trans['race_ethnicity']=='Black']\n",
    "    #white_stack = all_trans[all_trans['race_ethnicity']=='White']\n",
    "    return black_stack, white_stack\n",
    "\n",
    "clean_black_stack, clean_white_stack = split_white_black(clean_transcripts_wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total count of cleaned words (including repeated words) in CORAAL and VOC\n",
    "\n",
    "def find_word_counts(transcript, column):\n",
    "    transcript['words'] = transcript.apply(lambda x: x[column].split(), axis=1)\n",
    "    word_sum = transcript.words.sum()\n",
    "    output=collections.Counter(word_sum)\n",
    "    df = pd.DataFrame.from_dict(output, orient='index').reset_index()\n",
    "    df.columns = ['word', column+'_count']\n",
    "    print(column, len(df))\n",
    "    return df\n",
    "\n",
    "count_coraal_words = find_word_counts(clean_black_stack, 'clean_content')\n",
    "count_voc_words = find_word_counts(clean_white_stack, 'clean_content')\n",
    "\n",
    "# Find word counts in each ASR lexicon (where 'word' column contains unique words)\n",
    "unique_google_words = find_word_counts(clean_transcripts_wer, 'clean_google')\n",
    "unique_amazon_words = find_word_counts(clean_transcripts_wer, 'clean_amazon')\n",
    "unique_msft_words = find_word_counts(clean_transcripts_wer, 'clean_msft')\n",
    "unique_ibm_words = find_word_counts(clean_transcripts_wer, 'clean_ibm')\n",
    "unique_apple_words = find_word_counts(clean_transcripts_wer, 'clean_apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge to match CORAAL / VOC words to ASR lexicon\n",
    "\n",
    "coraal_merge_words = count_coraal_words\n",
    "voc_merge_words = count_voc_words\n",
    "\n",
    "for df in [unique_google_words, unique_amazon_words, unique_msft_words, unique_ibm_words, unique_apple_words]:\n",
    "    coraal_merge_words = coraal_merge_words.merge(df, on = 'word', how = 'left')\n",
    "    voc_merge_words = voc_merge_words.merge(df, on = 'word', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word sum\n",
    "\n",
    "total_coraal_words = coraal_merge_words['clean_content_count'].sum()\n",
    "total_voc_words = voc_merge_words['clean_content_count'].sum()\n",
    "\n",
    "asr_list = ['apple', 'ibm', 'google', 'amazon', 'msft']\n",
    "coraal_list = []\n",
    "voc_list = []\n",
    "\n",
    "for asr in asr_list:\n",
    "    voc_words_in_corpus = voc_merge_words['clean_content_count'].where(\n",
    "        ~voc_merge_words['clean_'+asr+'_count'].isna()).sum()\n",
    "    voc_list.append(voc_words_in_corpus/total_voc_words)\n",
    "    \n",
    "    coraal_words_in_corpus = coraal_merge_words['clean_content_count'].where(\n",
    "        ~coraal_merge_words['clean_'+asr+'_count'].isna()).sum()\n",
    "    coraal_list.append(coraal_words_in_corpus/total_coraal_words)\n",
    "\n",
    "asr_list_cap = ['Apple', 'IBM', 'Google', 'Amazon', 'Microsoft']\n",
    "coraal_list_round = [str(round(100*elem, 2))+'%' for elem in coraal_list]    \n",
    "voc_list_round = [str(round(100*elem, 2))+'%' for elem in voc_list]\n",
    "pd.DataFrame(list(zip(asr_list_cap, coraal_list_round, voc_list_round)), columns = ['ASR', \n",
    "                                                                    'CORAAL % Words in ASR Corpus', \n",
    "                                                                    'VOC % Words in ASR Corpus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check the count of Google ASR words\n",
    "\n",
    "print(total_coraal_words) # Total number of words uttered by black speakers in our sample\n",
    "print(coraal_merge_words['clean_content_count'].where(~coraal_merge_words['clean_google_count'].isna()).sum()) # Words that Google had in ASR from CORAAL\n",
    "\n",
    "print(total_voc_words) # Total number of words uttered by black speakers in our sample\n",
    "print(voc_merge_words['clean_content_count'].where(~voc_merge_words['clean_google_count'].isna()).sum()) # Words that Google had in ASR from VOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find set intersection and differences between VOC and CORAAL\n",
    "\n",
    "black_words = count_coraal_words['word']\n",
    "white_words = count_voc_words['word']\n",
    "\n",
    "black_not_in_white = black_words[~((black_words.isin(white_words)))]\n",
    "white_not_in_black = white_words[~((white_words.isin(black_words)))]\n",
    "white_black_intersection = white_words[((white_words.isin(black_words)))]\n",
    "\n",
    "print(len(black_not_in_white), len(white_not_in_black), len(white_black_intersection))\n",
    "print(len(black_words), len(white_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find set intersection and differences between VOC and CORAAL\n",
    "\n",
    "black_not_in_white_counts = pd.DataFrame(black_not_in_white).merge(count_coraal_words, on = 'word')\n",
    "black_not_in_white_counts.columns = ['word', 'coraal_count']\n",
    "black_not_in_white_counts = black_not_in_white_counts.sort_values('coraal_count', ascending=False)\n",
    "\n",
    "white_not_in_black_counts = pd.DataFrame(white_not_in_black).merge(count_voc_words, on = 'word')\n",
    "white_not_in_black_counts.columns = ['word', 'voc_count']\n",
    "white_not_in_black_counts = white_not_in_black_counts.sort_values('voc_count', ascending=False)\n",
    "\n",
    "white_black_intersection_counts = (pd.DataFrame(white_black_intersection).merge(count_coraal_words, on = 'word')).merge(count_voc_words, on='word')\n",
    "white_black_intersection_counts.columns = ['word', 'coraal_count', 'voc_count']\n",
    "white_black_intersection_counts['total_count'] = white_black_intersection_counts['coraal_count'] + white_black_intersection_counts['voc_count']\n",
    "white_black_intersection_counts = white_black_intersection_counts.sort_values('total_count', ascending=False)\n",
    "white_black_intersection_counts\n",
    "\n",
    "print(len(black_not_in_white_counts), len(white_not_in_black_counts), len(white_black_intersection_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_not_in_white_counts.to_csv('black_not_in_white_counts.csv', index = None)\n",
    "white_not_in_black_counts.to_csv('white_not_in_black_counts.csv', index = None)\n",
    "white_black_intersection_counts.to_csv('white_black_intersection_counts.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "state": {
    "8749f5dc7e9345ca820020277385c2a9": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
