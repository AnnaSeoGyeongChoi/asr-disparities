{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.6 (default, Dec 30 2019, 19:38:28) \n",
      "[Clang 11.0.0 (clang-1100.0.33.16)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()\n",
    "#os.chdir('..')\n",
    "base_folder = '/Users/allisonkoenecke/GitHub/fair-speech/release/'#'~/GitHub/fair-speech/release/' #os.getcwd()+'/' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get input files; construct segments from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make corrections to spelling of VOC metadata\n",
    "voc_metadata = pd.read_csv(base_folder + 'inputs/VOC/CSVOC_demo_info.csv', index_col=None)\n",
    "\n",
    "voc_metadata['update_speaker_code'] = voc_metadata['speaker_code']\n",
    "\n",
    "voc_metadata['update_speaker_code'] = np.where(voc_metadata['speaker_code'] == 'HUM_McLoughlin_Rachel', 'HUM_McLaughlin_Rachel', voc_metadata['update_speaker_code'])\n",
    "voc_metadata['update_speaker_code'] = np.where(voc_metadata['speaker_code'] == 'SAC_Vrilakas_Ron', 'SAC_Vrikalis_Ron', voc_metadata['update_speaker_code'])\n",
    "voc_metadata['update_speaker_code'] = np.where(voc_metadata['speaker_code'] == 'SAC_Arghittu_Allen', 'SAC_Argittu_Allen', voc_metadata['update_speaker_code'])\n",
    "voc_metadata['update_speaker_code'] = np.where(voc_metadata['speaker_code'] == 'SAC_Werner_Savannah', 'SAC_WernerRitchie_Savannah', voc_metadata['update_speaker_code'])\n",
    "voc_metadata['update_speaker_code'] = np.where(voc_metadata['speaker_code'] == 'HUM_Yoho_Meadow ', 'HUM_Yoho_Meadow', voc_metadata['update_speaker_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove times that occur during VOC wordlist reading\n",
    "wordlist_path = base_folder + 'inputs/VOC/wordlist_timestamps.txt'\n",
    "\n",
    "wordlist = pd.read_csv(wordlist_path, sep='\\t')\n",
    "first_starts = {f[:f.find('.')]: fs for f, fs, ls in wordlist[['filename', 'first_start', 'last_start']].values if 0 < fs < ls}\n",
    "last_starts = {f[:f.find('.')]: ls for f, fs, ls in wordlist[['filename', 'first_start', 'last_start']].values if 0 < fs < ls}\n",
    "\n",
    "def in_word_list(basefile, start_time):\n",
    "    if basefile not in first_starts or basefile not in last_starts:\n",
    "        return False\n",
    "    first_start = round(first_starts[basefile], 3)\n",
    "    last_start = round(last_starts[basefile], 3)\n",
    "    return first_start <= round(start_time, 3) <= last_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VOC transcripts\n",
    "\n",
    "def load_voc_text(project_path):\n",
    "    file_pattern = os.path.join(project_path, '*', 'transcripts', '*.txt')\n",
    "    filenames = sorted(glob.glob(file_pattern, recursive=True))\n",
    "    dataframes = []\n",
    "    for filename in filenames:\n",
    "        df = pd.read_csv(filename, sep='\\t', names=['name', 'speaker', 'start_time', 'end_time', 'content'])\n",
    "        df['filename'] = filename\n",
    "        df['location'] = filename.split('/')[-3]\n",
    "\n",
    "        dataframes.append(df)\n",
    "\n",
    "    df = pd.concat(dataframes)\n",
    "\n",
    "    df['source'] = 'voc'\n",
    "    df = df.sort_values(['filename', 'start_time'])\n",
    "    df['speaker'] = [name if str(speaker) == 'nan' else speaker for name, speaker in df[['name', 'speaker']].values]\n",
    "    df['basefile'] = [os.path.splitext(os.path.basename(f))[0] for f in df['filename']]\n",
    "\n",
    "    speakers = {b: None for b in df.basefile}\n",
    "    for name, basefile in df[['name', 'basefile']].drop_duplicates().values:\n",
    "        first_name_from_filename = basefile.split('_')[2]\n",
    "        last_name_from_filename = basefile.split('_')[1]\n",
    "        fname_l = first_name_from_filename.lower()\n",
    "        lname_l = last_name_from_filename.lower()\n",
    "        name_l = name.lower()\n",
    "        if fname_l in name_l or lname_l in name_l:\n",
    "            speakers[basefile] = name\n",
    "\n",
    "    # Exceptions \n",
    "    speakers['HUM_Givins_Patsy'] = \"interviewee\"\n",
    "    speakers['HUM_Gossi_Hannah'] = \"subject\"\n",
    "    speakers['HUM_Guynup_Taya'] = \"subject\"\n",
    "    speakers['HUM_Urban_Richard'] = \"Rick\"\n",
    "    speakers['MER_Coane_Sherry'] = 'SUB [main]'\n",
    "\n",
    "    # Create column whether this transcript line is by the interviewee for not.\n",
    "    df['interviewee'] = [speakers[basefile] == name or name == 'speaker' for basefile, name in df[['basefile', 'name']].values]\n",
    "    \n",
    "    df = df.sort_values(by=['basefile', 'start_time'])\n",
    "    df['line'] = np.arange(len(df))\n",
    "    df['wordlist'] = [in_word_list(b, s) for b, s in df[['basefile', 'start_time']].values]\n",
    "    df[df.wordlist]\n",
    "    \n",
    "    df = df[['basefile', 'line', 'start_time', 'end_time', 'speaker', 'content', 'interviewee', 'wordlist', 'source', 'location', 'name', 'filename']]\n",
    "    df.content = df.content.values.astype(str)\n",
    "    print(\"VOC full df length\", len(df))\n",
    "    df.drop_duplicates()    \n",
    "    print(\"VOC dedup df length\", len(df))    \n",
    "    full_df = df.merge(voc_metadata, left_on=['basefile'], right_on=['update_speaker_code'], how = 'left')\n",
    "    print(\"VOC merged metadata length\", len(full_df))\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CORAAL transcripts\n",
    "\n",
    "def load_coraal_text(project_path):\n",
    "    \n",
    "    file_pattern = os.path.join(project_path, '*metadata*.txt')\n",
    "    filenames = glob.glob(file_pattern, recursive=True)\n",
    "    print(filenames)\n",
    "    metadata = pd.concat([pd.read_csv(filename, sep='\\t') for filename in filenames], sort=False)\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for sub, file in metadata[['CORAAL.Sub', 'CORAAL.File']].drop_duplicates().values:\n",
    "        subpath = os.path.join(project_path, sub.lower())\n",
    "        text_filename = os.path.join(subpath, 'transcripts', file + '.txt')\n",
    "\n",
    "        text = pd.read_csv(text_filename, sep='\\t')\n",
    "        text['pause'] = text.Content.str.contains('(pause \\d+(\\.\\d{1,2})?)')\n",
    "        text = text[~text.pause]\n",
    "        \n",
    "        for spkr, sttime, content, entime in text[['Spkr', 'StTime', 'Content', 'EnTime']].values:\n",
    "            row = {\n",
    "                'name': spkr,\n",
    "                'speaker': spkr,\n",
    "                'start_time': sttime,\n",
    "                'end_time': entime,\n",
    "                'content': content,\n",
    "                'filename': text_filename,\n",
    "                'source': 'coraal',\n",
    "                'location': sub,\n",
    "                'basefile': file,\n",
    "                'interviewee': spkr in file\n",
    "            }\n",
    "            rows.append(row)\n",
    "        \n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.sort_values(by=['basefile', 'start_time'])\n",
    "    df['line'] = np.arange(len(df))\n",
    "    df = df[['basefile', 'line', 'start_time', 'end_time', 'speaker', 'content', 'interviewee', 'source', 'location', 'name', 'filename']]\n",
    "    print(\"CORAAL full df len \", len(df))\n",
    "    df.drop_duplicates()\n",
    "    print(\"CORAAL dedup df len \", len(df))\n",
    "    full_df = df.merge(metadata, left_on=['basefile', 'speaker'], right_on=['CORAAL.File', 'CORAAL.Spkr'], how = 'left')\n",
    "    print(\"CORAAL full merged metadata len \", len(full_df))\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define snippet segmentation\n",
    "\n",
    "def find_snippet(snippets, basefile, start_time, end_time):\n",
    "    start_time = round(start_time, 3)\n",
    "    end_time = round(end_time, 3)\n",
    "    match = snippets[(snippets.basefile == basefile) & (round(snippets.start_time, 3) == start_time) & (round(snippets.end_time, 3) == end_time)]\n",
    "    if len(match) == 0:\n",
    "        print(\"Snippet not found at {} from {} to {}\".format(basefile, start_time, end_time))\n",
    "    return match\n",
    "\n",
    "def segment_filename(basefilename, start_time, end_time, buffer):\n",
    "    start_time = int((start_time-buffer)*1000)\n",
    "    end_time = int((end_time+buffer)*1000)\n",
    "    filename = \"{}_{}_{}.wav\".format(basefilename, start_time, end_time)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct snippet segmentation of wav files -- not called in posted samples but used for wav files\n",
    "\n",
    "def create_segment(src_file, dst_dir, basefilename, start_time, end_time, buffer):\n",
    "    segment_basename = segment_filename(basefilename, start_time, end_time, buffer)\n",
    "    segment_file = os.path.join(dst_dir, segment_basename)\n",
    "    \n",
    "    if not os.path.isfile(src_file):\n",
    "        print(\"Error: Source file {} not found\".format(src_file))\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    audio = AudioSegment.from_wav(src_file)\n",
    "    start_time = int((start_time-buffer)*1000)\n",
    "    end_time = int((end_time+buffer)*1000)\n",
    "    clip = audio[start_time:end_time]\n",
    "    clip.export(segment_file, format=\"wav\")\n",
    "    return segment_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coraal_snippets(transcripts):\n",
    "    snippets = []\n",
    "    \n",
    "    for basefile in transcripts.basefile.unique():\n",
    "        df = transcripts[transcripts.basefile == basefile][['line', 'start_time', 'end_time', 'interviewee', 'content',\n",
    "                                                           'Gender', 'Age']]\n",
    "        backward_check = df['start_time'].values[1:] >= df['end_time'].values[:-1]\n",
    "        backward_check = np.insert(backward_check, 0, True)\n",
    "        forward_check = df['end_time'].values[:-1] <= df['start_time'].values[1:]\n",
    "        forward_check = np.insert(forward_check, len(forward_check), True)\n",
    "        df['use'] = backward_check & forward_check & df.interviewee \\\n",
    "            & ~df.content.str.contains('\\[') \\\n",
    "            & ~df.content.str.contains(']')\n",
    "        \n",
    "        values = df[['line', 'use']].values\n",
    "        snippet = []\n",
    "        for i in range(len(values)):\n",
    "            line, use = values[i]\n",
    "            if use:\n",
    "                snippet.append(line)\n",
    "            elif snippet: # if shouldn't use this line, but snippet exists\n",
    "                snippets.append(snippet)\n",
    "                snippet = []\n",
    "        if snippet:\n",
    "            snippets.append(snippet)\n",
    "            \n",
    "    basefiles = transcripts.basefile.values\n",
    "    start_times = transcripts.start_time.values\n",
    "    end_times = transcripts.end_time.values\n",
    "    contents = transcripts.content.values\n",
    "    gender = transcripts.Gender.values\n",
    "    age = transcripts.Age.values\n",
    "    rows = []\n",
    "    for indices in snippets:\n",
    "        rows.append({\n",
    "            'basefile': basefiles[indices[0]],\n",
    "            'start_time': start_times[indices[0]],\n",
    "            'end_time': end_times[indices[-1]],\n",
    "            'content': ' '.join(contents[indices]),\n",
    "            'age': age[indices[0]],\n",
    "            'gender': gender[indices[0]]\n",
    "        })\n",
    "    snippets = pd.DataFrame(rows)[['basefile', 'start_time', 'end_time', 'content', 'age', 'gender']]\n",
    "    snippets = snippets.sort_values(['basefile', 'start_time'])\n",
    "    snippets['duration'] = snippets.end_time - snippets.start_time\n",
    "    snippets['segment_filename'] = [segment_filename(b, s, e, buffer=0) for b, s, e in snippets[['basefile', 'start_time', 'end_time']].values]\n",
    "    return snippets\n",
    "\n",
    "\n",
    "def create_voc_snippets(transcripts):\n",
    "    snippets = []\n",
    "    \n",
    "    for basefile in transcripts.basefile.unique():\n",
    "        df = transcripts[transcripts.basefile == basefile][['line', 'start_time', 'end_time', 'interviewee', 'wordlist',\n",
    "                                                           'age_interview', 'gender', 'race_ethnicity', 'recording_quality']]\n",
    "        backward_check = df['start_time'].values[1:] >= df['end_time'].values[:-1]\n",
    "        backward_check = np.insert(backward_check, 0, True)\n",
    "        forward_check = df['end_time'].values[:-1] <= df['start_time'].values[1:]\n",
    "        forward_check = np.insert(forward_check, len(forward_check), True)\n",
    "        df['use'] = backward_check & forward_check & df.interviewee & ~df.wordlist\n",
    "        \n",
    "        values = df[['line', 'use']].values\n",
    "        snippet = []\n",
    "        for i in range(len(values)):\n",
    "            line, use = values[i]\n",
    "            if use:\n",
    "                snippet.append(line)\n",
    "            elif snippet: # if shouldn't use this line, but snippet exists\n",
    "                snippets.append(snippet)\n",
    "                snippet = []\n",
    "        if snippet:\n",
    "            snippets.append(snippet)\n",
    "            \n",
    "    basefiles = transcripts.basefile.values\n",
    "    start_times = transcripts.start_time.values\n",
    "    end_times = transcripts.end_time.values\n",
    "    contents = transcripts.content.values\n",
    "    age_interview = transcripts.age_interview.values\n",
    "    gender = transcripts.gender.values\n",
    "    race_ethnicity = transcripts.race_ethnicity.values\n",
    "    recording_quality = transcripts.recording_quality.values\n",
    "    \n",
    "    rows = []\n",
    "    for indices in snippets:\n",
    "        rows.append({\n",
    "            'basefile': basefiles[indices[0]],\n",
    "            'start_time': start_times[indices[0]],\n",
    "            'end_time': end_times[indices[-1]],\n",
    "            'content': ' '.join(contents[indices]),\n",
    "            'age': age_interview[indices[0]],\n",
    "            'gender': gender[indices[0]],\n",
    "            'race_ethnicity': race_ethnicity[indices[0]],\n",
    "            'recording_quality': recording_quality[indices[0]]\n",
    "        })\n",
    "    snippets = pd.DataFrame(rows)[['basefile', 'start_time', 'end_time', 'content', \n",
    "                                  'age', 'gender', 'race_ethnicity', 'recording_quality']]\n",
    "    snippets = snippets.sort_values(['basefile', 'start_time'])\n",
    "    snippets['duration'] = snippets.end_time - snippets.start_time\n",
    "    snippets['segment_filename'] = [segment_filename(b, s, e, buffer=0) for b, s, e in snippets[['basefile', 'start_time', 'end_time']].values]\n",
    "    return snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VOC snippets\n",
    "voc_transcripts = load_voc_text(base_folder+'/inputs/VOC')\n",
    "voc_snippets = create_voc_snippets(voc_transcripts)\n",
    "\n",
    "# These snippets should exist, run these pre-filtering on duration\n",
    "assert len(find_snippet(voc_snippets, 'HUM_Mahony-Moyer_Evan', 14.455, 15.585)) > 0\n",
    "assert len(find_snippet(voc_snippets, 'HUM_Mahony-Moyer_Evan', 27.565, 71.780)) > 0\n",
    "assert len(find_snippet(voc_snippets, 'HUM_Mahony-Moyer_Evan', 85.481, 143.376)) > 0\n",
    "assert len(find_snippet(voc_snippets, 'HUM_Mahony-Moyer_Evan', 317.795, 338.481)) > 0\n",
    "assert len(find_snippet(voc_snippets, 'HUM_Mahony-Moyer_Evan', 373.935, 394.101)) > 0\n",
    "assert len(find_snippet(voc_snippets, 'HUM_Mahony-Moyer_Evan', 500.096, 554.731)) > 0\n",
    "assert len(find_snippet(voc_snippets, 'HUM_Mahony-Moyer_Evan', 555.633, 561.268)) > 0\n",
    "assert len(find_snippet(voc_snippets, 'HUM_Mahony-Moyer_Evan', 577.171, 594.601)) > 0\n",
    "assert len(find_snippet(voc_snippets, 'HUM_Mahony-Moyer_Evan', 597.701, 601.543)) > 0\n",
    "assert len(find_snippet(voc_snippets, 'HUM_Mahony-Moyer_Evan', 661.386, 663.990)) > 0\n",
    "\n",
    "# check for nonoverlapping snippets\n",
    "interviewees = {b: s for b, s in voc_transcripts[voc_transcripts.interviewee][['basefile', 'speaker']].drop_duplicates().values}\n",
    "\n",
    "for basefile, start_time, end_time in (voc_snippets[['basefile', 'start_time', 'end_time']].values):\n",
    "    xscript_speakers = voc_transcripts[(voc_transcripts.basefile == basefile)\n",
    "                      & (voc_transcripts.start_time >= start_time)\n",
    "                      & (voc_transcripts.end_time <= end_time)].speaker.unique()\n",
    "    if len(xscript_speakers) < 1:\n",
    "        print(basefile, start_time, end_time)\n",
    "        assert 0\n",
    "    if not (len(xscript_speakers) == 1 and xscript_speakers[0] == interviewees[basefile]):\n",
    "        print(basefile, start_time, end_time)\n",
    "        assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/allisonkoenecke/GitHub/fair-speech/release//inputs/CORAAL/DCB_metadata_2018.10.06.txt', '/Users/allisonkoenecke/GitHub/fair-speech/release//inputs/CORAAL/PRV_metadata_2018.10.06.txt', '/Users/allisonkoenecke/GitHub/fair-speech/release//inputs/CORAAL/ROC_metadata_2018.10.06.txt']\n",
      "CORAAL full df len  136725\n",
      "CORAAL dedup df len  136725\n",
      "CORAAL full merged metadata len  136725\n"
     ]
    }
   ],
   "source": [
    "# Create CORAAL snippets\n",
    "coraal_transcripts = load_coraal_text(base_folder+'/inputs/CORAAL')\n",
    "coraal_snippets = create_coraal_snippets(coraal_transcripts)\n",
    "\n",
    "# These snippets should exist, run these pre-filtering on duration\n",
    "assert len(find_snippet(coraal_snippets, 'DCB_se1_ag1_f_01_1', 8.9467, 12.4571)) > 0\n",
    "assert len(find_snippet(coraal_snippets, 'DCB_se1_ag1_f_01_1', 364.6292, 382.2063)) > 0\n",
    "assert len(find_snippet(coraal_snippets, 'DCB_se1_ag1_f_01_1', 17.0216, 19.5291)) > 0\n",
    "assert len(find_snippet(coraal_snippets, 'DCB_se1_ag1_f_01_1', 875.0084, 876.5177)) > 0\n",
    "assert len(find_snippet(coraal_snippets, 'DCB_se1_ag1_f_01_1', 885.9359, 886.3602)) > 0\n",
    "assert len(find_snippet(coraal_snippets, 'DCB_se1_ag1_f_01_1', 890.9707, 894.35)) > 0\n",
    "assert len(find_snippet(coraal_snippets, 'DCB_se1_ag1_f_01_1', 895.9076, 910.211)) > 0\n",
    "\n",
    "assert len(coraal_snippets[(coraal_snippets.content.str.contains('\\[')) | (coraal_snippets.content.str.contains('\\]'))]) == 0\n",
    "interviewees = {b: s for b, s in coraal_transcripts[coraal_transcripts.interviewee][['basefile', 'speaker']].drop_duplicates().values}\n",
    "\n",
    "for basefile, start_time, end_time in (coraal_snippets[['basefile', 'start_time', 'end_time']].values):\n",
    "    xscript_speakers = coraal_transcripts[(coraal_transcripts.basefile == basefile)\n",
    "                      & (coraal_transcripts.start_time >= start_time)\n",
    "                      & (coraal_transcripts.end_time <= end_time)].speaker.unique()\n",
    "    if len(xscript_speakers) < 1:\n",
    "        print(basefile, start_time, end_time)\n",
    "        assert 0\n",
    "    if not (len(xscript_speakers) == 1 and xscript_speakers[0] == interviewees[basefile]):\n",
    "        print(basefile, start_time, end_time)\n",
    "        assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basefile</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>content</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>duration</th>\n",
       "      <th>segment_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DCB_se1_ag1_f_01_1</td>\n",
       "      <td>8.9467</td>\n",
       "      <td>12.4571</td>\n",
       "      <td>/RD-NAME-3/ and today's date is the seventh.</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>3.5104</td>\n",
       "      <td>DCB_se1_ag1_f_01_1_8946_12457.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DCB_se1_ag1_f_01_1</td>\n",
       "      <td>17.0216</td>\n",
       "      <td>19.5291</td>\n",
       "      <td>I was born on October tenth, nineteen ninety s...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>2.5075</td>\n",
       "      <td>DCB_se1_ag1_f_01_1_17021_19529.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DCB_se1_ag1_f_01_1</td>\n",
       "      <td>24.6245</td>\n",
       "      <td>26.5083</td>\n",
       "      <td>I grew up in Kenilworth.</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>1.8838</td>\n",
       "      <td>DCB_se1_ag1_f_01_1_24624_26508.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DCB_se1_ag1_f_01_1</td>\n",
       "      <td>31.3939</td>\n",
       "      <td>32.1633</td>\n",
       "      <td>Yes.</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.7694</td>\n",
       "      <td>DCB_se1_ag1_f_01_1_31393_32163.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DCB_se1_ag1_f_01_1</td>\n",
       "      <td>38.6529</td>\n",
       "      <td>39.2451</td>\n",
       "      <td>/RD-SCHOOL-2/.</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>DCB_se1_ag1_f_01_1_38652_39245.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15231</th>\n",
       "      <td>ROC_se0_ag3_m_01_1</td>\n",
       "      <td>3100.8430</td>\n",
       "      <td>3178.3310</td>\n",
       "      <td>Well, once again, you know I- I like Rochester...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>77.4880</td>\n",
       "      <td>ROC_se0_ag3_m_01_1_3100843_3178331.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15232</th>\n",
       "      <td>ROC_se0_ag3_m_01_1</td>\n",
       "      <td>3179.1914</td>\n",
       "      <td>3179.5099</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>ROC_se0_ag3_m_01_1_3179191_3179509.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15233</th>\n",
       "      <td>ROC_se0_ag3_m_01_1</td>\n",
       "      <td>3187.7801</td>\n",
       "      <td>3188.2434</td>\n",
       "      <td>Sure.</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.4633</td>\n",
       "      <td>ROC_se0_ag3_m_01_1_3187780_3188243.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15234</th>\n",
       "      <td>ROC_se0_ag3_m_01_1</td>\n",
       "      <td>3189.0045</td>\n",
       "      <td>3189.5057</td>\n",
       "      <td>Yes,</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.5012</td>\n",
       "      <td>ROC_se0_ag3_m_01_1_3189004_3189505.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15235</th>\n",
       "      <td>ROC_se0_ag3_m_01_1</td>\n",
       "      <td>3192.5840</td>\n",
       "      <td>3193.6583</td>\n",
       "      <td>I hope I've contributed.</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1.0743</td>\n",
       "      <td>ROC_se0_ag3_m_01_1_3192584_3193658.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15236 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 basefile  start_time   end_time  \\\n",
       "0      DCB_se1_ag1_f_01_1      8.9467    12.4571   \n",
       "1      DCB_se1_ag1_f_01_1     17.0216    19.5291   \n",
       "2      DCB_se1_ag1_f_01_1     24.6245    26.5083   \n",
       "3      DCB_se1_ag1_f_01_1     31.3939    32.1633   \n",
       "4      DCB_se1_ag1_f_01_1     38.6529    39.2451   \n",
       "...                   ...         ...        ...   \n",
       "15231  ROC_se0_ag3_m_01_1   3100.8430  3178.3310   \n",
       "15232  ROC_se0_ag3_m_01_1   3179.1914  3179.5099   \n",
       "15233  ROC_se0_ag3_m_01_1   3187.7801  3188.2434   \n",
       "15234  ROC_se0_ag3_m_01_1   3189.0045  3189.5057   \n",
       "15235  ROC_se0_ag3_m_01_1   3192.5840  3193.6583   \n",
       "\n",
       "                                                 content   age  gender  \\\n",
       "0           /RD-NAME-3/ and today's date is the seventh.  17.0  Female   \n",
       "1      I was born on October tenth, nineteen ninety s...  17.0  Female   \n",
       "2                               I grew up in Kenilworth.  17.0  Female   \n",
       "3                                                   Yes.  17.0  Female   \n",
       "4                                         /RD-SCHOOL-2/.  17.0  Female   \n",
       "...                                                  ...   ...     ...   \n",
       "15231  Well, once again, you know I- I like Rochester...  63.0    Male   \n",
       "15232                                              Yeah.  63.0    Male   \n",
       "15233                                              Sure.  63.0    Male   \n",
       "15234                                               Yes,  63.0    Male   \n",
       "15235                           I hope I've contributed.  63.0    Male   \n",
       "\n",
       "       duration                        segment_filename  \n",
       "0        3.5104       DCB_se1_ag1_f_01_1_8946_12457.wav  \n",
       "1        2.5075      DCB_se1_ag1_f_01_1_17021_19529.wav  \n",
       "2        1.8838      DCB_se1_ag1_f_01_1_24624_26508.wav  \n",
       "3        0.7694      DCB_se1_ag1_f_01_1_31393_32163.wav  \n",
       "4        0.5922      DCB_se1_ag1_f_01_1_38652_39245.wav  \n",
       "...         ...                                     ...  \n",
       "15231   77.4880  ROC_se0_ag3_m_01_1_3100843_3178331.wav  \n",
       "15232    0.3185  ROC_se0_ag3_m_01_1_3179191_3179509.wav  \n",
       "15233    0.4633  ROC_se0_ag3_m_01_1_3187780_3188243.wav  \n",
       "15234    0.5012  ROC_se0_ag3_m_01_1_3189004_3189505.wav  \n",
       "15235    1.0743  ROC_se0_ag3_m_01_1_3192584_3193658.wav  \n",
       "\n",
       "[15236 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coraal_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make 5-50 second snippets for VOC and CORAAL\n",
    "\n",
    "min_duration = 5 # in seconds\n",
    "max_duration = 50 # in seconds\n",
    "\n",
    "#VOC\n",
    "voc_snippets = voc_snippets[(min_duration <= voc_snippets.duration) & (voc_snippets.duration <= max_duration)]\n",
    "print(voc_snippets.duration.describe())\n",
    "\n",
    "#CORAAL\n",
    "coraal_snippets = coraal_snippets[(min_duration <= coraal_snippets.duration) & (coraal_snippets.duration <= max_duration)]\n",
    "print(coraal_snippets.duration.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_snippets = voc_snippets[['basefile', 'start_time', 'end_time', 'content', 'duration', 'segment_filename']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_snippets.to_csv(base_folder + 'inputs/VOC/voc_snippets.tsv', sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coraal_snippets.to_csv(base_folder + 'inputs/CORAAL/coraal_snippets.tsv', sep = '\\t', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "state": {
    "8749f5dc7e9345ca820020277385c2a9": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
